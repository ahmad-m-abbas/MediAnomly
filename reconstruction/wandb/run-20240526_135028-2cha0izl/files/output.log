============= Configurations =============
dataset:rsna
model:ganomaly
in_channels:1
input_size:64
base_width:16
expansion:1
mid_num:1024
latent_size:16
en_num_layers:1
de_num_layers:1
epochs:250
batch_size:64
lr:0.001
weight_decay:0
seed:42
num_params:3.5202M
FLOPs:36.5773M
=> Initial learning rate: 0.001
Traceback (most recent call last):
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/train.py", line 44, in <module>
    main()
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/train.py", line 40, in main
    worker.run_train()
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/utils/ganomaly_worker.py", line 57, in run_train
    g_loss, adv_loss, recon_loss, enc_loss, d_loss = self.train_epoch()
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/utils/ganomaly_worker.py", line 41, in train_epoch
    loss_d.backward()
  File "/home/ahmad/anaconda3/envs/torch/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ahmad/anaconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/ahmad/anaconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/graph.py", line 690, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1024, 16]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).