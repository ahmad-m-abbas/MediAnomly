============= Configurations =============
dataset:brats
model:ae
in_channels:1
input_size:64
base_width:16
expansion:1
mid_num:1024
latent_size:16
en_num_layers:1
de_num_layers:1
epochs:250
batch_size:64
lr:0.001
weight_decay:0
seed:445793
num_params:2.3512M
FLOPs:29.8967M
=> Initial learning rate: 0.001
Traceback (most recent call last):
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/train.py", line 43, in <module>
    main()
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/train.py", line 39, in main
    worker.run_train()
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/utils/ae_worker.py", line 219, in run_train
    train_loss = self.train_epoch()
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/utils/ae_worker.py", line 34, in train_epoch
    loss = self.criterion(img, net_out)
  File "/home/ahmad/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ahmad/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ahmad/Desktop/Graduation Proj/MedIAnomaly/reconstruction/utils/losses.py", line 36, in forward
    total_loss = recon_loss + embedding_loss
RuntimeError: The size of tensor a (64) must match the size of tensor b (16) at non-singleton dimension 3